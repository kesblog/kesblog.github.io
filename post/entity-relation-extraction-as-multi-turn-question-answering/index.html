<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>KesBlog</title>
<meta name="description" content="Every 🐦 has an 🦅's dream." />
<link rel="shortcut icon" href="https://kesblog.github.io/favicon.ico?v=1569316029350">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
<link href="https://cdn.remixicon.com/releases/v1.3.1/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.7.2/animate.min.css">

<link rel="stylesheet" href="https://kesblog.github.io/styles/main.css">
<link rel="alternate" type="application/atom+xml" title="KesBlog - Atom Feed" href="https://kesblog.github.io/atom.xml">



  </head>
  <body>
    <div id="app" class="main px-4 flex flex-col lg:flex-row">
      <div id="sidebar" class="sidebar-wrapper lg:static lg:w-1/4">
  <div class="lg:sticky top-0">
    <div class="sidebar-content">
      <div class="flex lg:block p-4 lg:px-0 items-center fixed lg:static lg:block top-0 right-0 left-0 bg-white z-50">
        <i class="remixicon-menu-2-line lg:mt-4 text-2xl cursor-pointer animated fadeIn" onclick="openMenu()"></i>
        <a href="https://kesblog.github.io">
          <img class="animated fadeInLeft avatar rounded-lg mx-4 lg:mt-32 lg:mx-0 mt-0 lg:w-24 lg:h-24 w-12 w-12" src="https://kesblog.github.io/images/avatar.png?v=1569316029350" alt="">
        </a>
        <h1 class="animated fadeInLeft lg:text-4xl font-extrabold lg:mt-8 mt-0 text-xl" style="animation-delay: 0.2s">KesBlog</h1>
      </div>
      
        <div class="animated fadeInLeft" style="animation-delay: 0.4s">
          <p class="my-4 text-gray-600 font-light hidden lg:block">
            文章目录
          </p>
          <div class="toc-container hidden lg:block">
            <ul class="markdownIt-TOC">
<li>
<ul>
<li><a href="#%E4%BB%8B%E7%BB%8D">介绍</a></li>
<li><a href="#%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C">相关工作</a>
<ul>
<li><a href="#%E6%8F%90%E5%8F%96%E5%AE%9E%E4%BD%93%E5%92%8C%E5%85%B3%E7%B3%BB">提取实体和关系</a></li>
<li><a href="#%E6%9C%BA%E5%99%A8%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3">机器阅读理解</a></li>
</ul>
</li>
<li><a href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E5%92%8C%E4%BB%BB%E5%8A%A1">数据集和任务</a>
<ul>
<li><a href="#ace04ace05-%E5%92%8C-conll04">ACE04，ACE05 和 CoNLL04</a></li>
<li><a href="#resume%E4%B8%80%E4%B8%AA%E6%96%B0%E6%9E%84%E5%BB%BA%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86">RESUME：一个新构建的数据集</a></li>
</ul>
</li>
<li><a href="#%E6%A8%A1%E5%9E%8B">模型</a>
<ul>
<li><a href="#%E7%B3%BB%E7%BB%9F%E6%80%BB%E8%A7%88">系统总览</a></li>
<li><a href="#%E4%BD%BF%E7%94%A8%E6%A8%A1%E7%89%88%E7%94%9F%E6%88%90%E9%97%AE%E9%A2%98">使用模版生成问题</a></li>
<li><a href="#%E9%80%9A%E8%BF%87mrc%E6%9D%A5%E6%8A%BD%E5%8F%96%E7%AD%94%E6%A1%88">通过MRC来抽取答案</a></li>
<li><a href="#%E5%A2%9E%E5%BC%BA%E5%AD%A6%E4%B9%A0">增强学习</a></li>
</ul>
</li>
<li><a href="#%E5%AE%9E%E9%AA%8C">实验</a>
<ul>
<li><a href="#resume%E4%B8%8A%E7%9A%84%E7%BB%93%E6%9E%9C">RESUME上的结果</a></li>
<li><a href="#ace04ace05%E5%92%8Cconll04%E4%B8%8A%E7%9A%84%E8%A1%A8%E7%8E%B0">ACE04，ACE05和CoNLL04上的表现</a></li>
</ul>
</li>
<li><a href="#%E6%A8%A1%E5%9E%8B%E7%AE%80%E5%8C%96%E6%B5%8B%E8%AF%95">模型简化测试</a>
<ul>
<li><a href="#%E9%97%AE%E9%A2%98%E7%94%9F%E6%88%90%E7%AD%96%E7%95%A5%E7%9A%84%E5%BD%B1%E5%93%8D">问题生成策略的影响</a></li>
<li><a href="#%E8%81%94%E5%90%88%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BD%B1%E5%93%8D">联合学习的影响</a></li>
<li><a href="#%E6%A0%B7%E4%BE%8B%E5%AD%A6%E4%B9%A0">样例学习</a></li>
</ul>
</li>
<li><a href="#%E7%BB%93%E8%AE%BA">结论</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      
    </div>
  </div>
</div>

<div class="menu-container">
  <i class="remixicon-arrow-left-line text-2xl cursor-pointer animated fadeIn close-menu-btn" onclick="closeMenu()"></i>
  <div>
    
      
        <a href="/" class="menu" style="animation-delay: 0s">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu" style="animation-delay: 0.2s">
          归档
        </a>
      
    
      
        <a href="/tags" class="menu" style="animation-delay: 0.4s">
          标签
        </a>
      
    
      
        <a href="/post/about" class="menu" style="animation-delay: 0.6000000000000001s">
          关于
        </a>
      
    
  </div>
  <div class="site-footer">
    <div class="py-4 text-gray-700">Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a></div>
    <a class="rss" href="https://kesblog.github.io/atom.xml" target="_blank">RSS</a>
  </div>
</div>
<div class="mask" onclick="closeMenu()">
</div>
      <div class="content-wrapper py-32 lg:p-8 lg:w-3/4 post-detail animated fadeIn">
        <h1 class="text-3xl font-bold lg:mt-16">Entity-Relation Extraction as Multi-turn Question Answering</h1>
        <div class="text-sm text-gray-700 lg:my-8">
          2019-08-27 / 14 min read
        </div>
        
          <img class="post-feature-image rounded-lg mx-auto my-4" src="https://kesblog.github.io/post-images/entity-relation-extraction-as-multi-turn-question-answering.png" alt="">
        
        <div class="post-content yue">
          <p>在这篇文章中，我们提出了一个新的实体关系抽取的范式。我们将这个任务转换成多轮问答问题，也就是说，将实体关系抽取任务转换成从文章中寻找问题答案的任务。这个多轮对话形式带来了一些关键的优势：首先，问题编码了我们想识别的实体关系类别的重要信息；然后，QA问题是一种联合建模实体和关系的自然的方法；最后，它可以让我们利用良好发展的机器阅读理解(MRC)模型。</p>
<!-- more -->
<p>在ACE和CoNLL04语料库上的实验显示我们的模型比之前的模型效果好。我们在ACE04、ACE05和CoNLL04数据集上取得了SOTA的成绩，分别将SOTA成绩提高到了49.4 (+1.0)、60.2 (+0.6) 和 68.9 (+2.1)。</p>
<p>此外，我们新构建了一个中文简历数据集 <strong>RESUME</strong>，要求多步推理来构建实体以来，和之前的只需要单步数据集不同。我们提出的多轮 QA模型在 RESUME 数据集上取得了最好的表现。</p>
<h2 id="介绍">介绍</h2>
<p>实体关系抽取最近越来越火热。要求将一段自然语言转换成结构化的知识。比如给一下文字：</p>
<blockquote>
<p>In 2002, Musk founded SpaceX, an aerospace manufacturer and space transport services Company, of which he is CEO and lead designer. He helped fund Tesla, Inc., an electric vehicle and so- lar panel manufacturer, in 2003, and became its CEO and product architect. In 2006, he inspired the creation of SolarCity, a solar energy services Company, and operates as its chairman. In 2016, he co-founded Neuralink, a neurotechnology Com- pany focused on developing brain–computer inter- faces, and is its CEO. In 2016, Musk founded The Boring Company, an infrastructure and tunnel- construction Company.</p>
</blockquote>
<p>我们需要提取四种不同的实体：Person，Company，Time 和 Position，三种类型的关系：FOUND，FOUNDING-TIME 和 SERVING-ROLE。这些文字被转化成结构化数据集，如表1所示：<br>
<img src="https://kesblog.github.io/post-images/1566905501587.png" alt=""></p>
<p>许多已存在的模型通过提取三元组列表来解决该任务，比如：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">REL</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msub><mi>e</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>e</mi><mn>2</mn></msub><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\operatorname{REL}\left(e_{1}, e_{2}\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">R</span><span class="mord mathrm">E</span><span class="mord mathrm">L</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span></span>，表示实体 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>e</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">e_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>e</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">e_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，之间存在关系<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">REL</mi><mo>⁡</mo></mrow><annotation encoding="application/x-tex">\operatorname{REL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mop"><span class="mord mathrm">R</span><span class="mord mathrm">E</span><span class="mord mathrm">L</span></span></span></span></span>，之前的模型大多有两种类型：</p>
<ul>
<li>首先使用标注模型检测实体，然后使用关系抽取模型来识别每对实体之间的关系</li>
<li>联合方法，使用不同的策略，比如限制或者参数共享，将实体模型和关系模型结合起来。</li>
</ul>
<p>这些问题有着一些问题，全部涉及到问题形式化和算法两个方面：</p>
<ul>
<li>从形式化层面来说，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">REL</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msub><mi>e</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>e</mi><mn>2</mn></msub><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\operatorname{REL}\left(e_{1}, e_{2}\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">R</span><span class="mord mathrm">E</span><span class="mord mathrm">L</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span></span> 三元组结构不能完全表达问题背后的关系。拿之前的 <em>Musk</em> 为例，这些标签之间有着层级关系：Time的抽取依赖着Position，因为一个Person可以担任不同的Position在不同的Time，Position的抽取也依赖着Company，因为一个Person可以为多个Company工作。</li>
<li>从算法层面来说，对于现存的关系抽取模型来说，模型的输入是一段文本，带着两个实体标签，输出是两个实体间是否存在该关系。Wang et al.(2016a); Zeng et al(2018) 曾指出，对于神经模型，很难捕捉到这种形式化层面下的语法语义等信息，尤其是当:
<ul>
<li>实体距离较远</li>
<li>一个实体参与多个关系</li>
<li>关系存在重叠。比如文本 A B C D中，(A，C)是一个对，(B，D)是另一个对。</li>
</ul>
</li>
</ul>
<p>将实体关系抽取任务当作多轮QA任务有着以下的好处：</p>
<ul>
<li>多轮QA的设置提供了编码层次化依赖的两个编码方法。在多轮对话的过程中，我们逐渐获取了下一轮对话所需要的实体信息。有点类似于多轮对话系统中的slot。</li>
<li>问题编码了我们想识别的关系类的重要先验信息。这些信息有可能解决现存关系抽取模型不能解决的问题，比如实体距离远、关系重叠的问题等等。</li>
<li>QA框架提供了一种同时抽取实体和关系的自然的方法。大多MRC模型支持输出一个特殊的 <strong>NONE</strong> 标签，表示对于问题没有答案。通过这个，原始的两个任务，实体提取和关系抽取可以被合并为一个单独的QA任务：如果返回的不是 <strong>NONE</strong>，说明关系存在，并且返回的实体正好是我们想要抽取的实体。</li>
</ul>
<p>在这篇文章中，我们展示了我们提出的范式，带来了巨大的效果提升。我们也展示了多轮QA的设定可以简单的继承增强学习来获得额外的效果提升。</p>
<p>第二节：相关工作</p>
<p>第三节：数据集和设定</p>
<p>第四节：模型</p>
<p>第五节：实验结果</p>
<p>第六节：结论</p>
<h2 id="相关工作">相关工作</h2>
<h3 id="提取实体和关系">提取实体和关系</h3>
<p>许多早期的实体关系抽取模型是流水线的：一个实体抽取模型来抽取感兴趣的实体，然后一个关系抽取模型来构造抽取出的实体之间的关系。</p>
<p>早起的联合学习模型通过多种依赖来联合两个模型。</p>
<p>另一种绑定两个模型的方法是使用增强学习或者最小风险训练。</p>
<h3 id="机器阅读理解">机器阅读理解</h3>
<p>在这篇文章中，我们提出了一个更加复杂的场景，层次化的依赖需要被建模，但轮QA无法解决。</p>
<h2 id="数据集和任务">数据集和任务</h2>
<h3 id="ace04ace05-和-conll04">ACE04，ACE05 和 CoNLL04</h3>
<p>我们使用被广泛使用的实体关系抽取的ACE04、ACE05和 CoNLL04数据集。</p>
<p>ACE04定义了7个实体类型，包括 Person(PER)，Organization(ORG)，Geographical Entities(GPE)，Location(LOC)，Facility(FAC)，Weapon(WEA) 和 Vehicle(VEH)。对于每对实体，定义了7种关系，包括：Physical(PHYS)，Person-Social(PER-SON)，Employment-Organization(EMP-ORG)，Agent-Artifact(ART)，PER/ORG Affiliation(OTHER-AFF)，GPE-Affiliation(GPE-AFF) 和 Discourse(DISC)。</p>
<p>ACE05在ACE04的基础上构建，保存了PER-SOC，ART和GPE-AFF 类别，但是将PHYS划分为PHYS和一个新的PART-WHOLE类别。它也删除了DISC类别，将EMP-ORG和OTHER-AFF合并为一个新的EMP-ORG类别。</p>
<p>对于CoNLL04数据集，定义了4个实体类别(LOC，ORG，PER 和 OTHERS)，和5个关系类别(LOCATED_IN，WORK_FOR，ORGBASED_IN，LIVE_IN 和 KILL)。</p>
<h3 id="resume一个新构建的数据集">RESUME：一个新构建的数据集</h3>
<p>前三个数据集是三元组抽取，两轮对话就足够了。这些数据集不包括我们之前说的层次实体关系抽取例子。</p>
<p>我们构建了一个新的数据集，叫做 <strong>RESUME</strong>。我们从IPO简介的管理团队描述中，抽取了841段。每段描述了一个经理的工作历程。中文的数据集，样例如下：</p>
<blockquote>
<p>郑强先生，本公司监事，1973年出生，中国国籍，无境外永久居留权。1995年，毕业 于南京大学经济管理专业；1995年至1998年， 就职于江苏常州公路运输有限公司，任主办 会计；1998年至2000年，就职于越秀会计师事 务所，任项目经理；2000年至2010年，就职于 国富浩华会计师事务所有限公司广东分所， 历任项目经理、部门经理、合伙人及副主任 会计师；2010年至2011年，就职于广东中科 招商创业投资管理有限责任公司，任副总经 理；2011年至今，任广东中广投资管理有限公 司董事、总经理；2016年至今，任湛江中广创 业投资有限公司董事、总经理；2016年3月至 今，担任本公司监事.</p>
</blockquote>
<p>我们识别四种类型实体：Person，Company，Position 和 Time。值得注意的是，一个人可以在不同的时间为不同的公司工作，一个人可以担任不同的职位在同一公司不同时间。</p>
<h2 id="模型">模型</h2>
<h3 id="系统总览">系统总览</h3>
<p>系统总览在算法1中，主要包含了两个步骤。<br>
<img src="https://kesblog.github.io/post-images/1566909358592.png" alt=""></p>
<ol>
<li>头实体抽取步骤(4-9行)：每次多轮QA由一个实体出发，为了抽取开始的实体，我们将每个实体类型转化为一个问题，使用 <strong>EntityQuesTemplates</strong>（第4行），实体 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>e</mi></mrow><annotation encoding="application/x-tex">e</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">e</span></span></span></span> 通过回答问题被抽取（第5行）。如果系统输出 <em>NONE</em> 标签，意味着句子不包含该种类型的实体。</li>
<li>关系和尾实体抽取阶段(10-24行)：ChainOfRelTemplates定义了一串的关系，我们需要根据这些顺序来进行多轮QA。原因是因为一些实体的抽取依赖着其他的抽取。举个例子，在 <strong>RESUME</strong>数据集中，经理职位实体的抽取依赖着他所在的公司等等。ChainOfRelTemplates 也定义了一些将被填充的槽。为了生成一个问题(14行)，我们将之前抽取的实体填充到模版的槽中。关系<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">REL</mi><mo>⁡</mo></mrow><annotation encoding="application/x-tex">\operatorname{REL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mop"><span class="mord mathrm">R</span><span class="mord mathrm">E</span><span class="mord mathrm">L</span></span></span></span></span> 和尾实体 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>e</mi></mrow><annotation encoding="application/x-tex">e</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">e</span></span></span></span> 将会联合的被抽取。如果返回 <em>NONE</em>，意味着句子中没有问题的答案。</li>
</ol>
<p>值得注意的是，头实体抽取阶段抽取的实体并不都是头实体。在后续的阶段，这些实体先被假设为头实体，如果真的是头实体，QA模型将会通过回答问题来抽取出相应的关系和尾实体，否则返回<em>NONE</em>，该实体将会被忽略。</p>
<p>对于前三个数据集，两轮QA就足够了，ChainOfRelTemplates包含了1轮，对于 RESUME，需要抽取4个实体，ChainOfRelTemplates包含了3轮。</p>
<h3 id="使用模版生成问题">使用模版生成问题</h3>
<p>每个实体类型和由模版生成的类型特定的问题相关连。有两种方法来基于模版生成问题：自然语言问题和伪问题。一个伪问题不一定遵循语法。举例来说：</p>
<ul>
<li>自然语言问题：Which fa- cility is mentioned in the text</li>
<li>伪问题：entity: facility</li>
</ul>
<p>在关系和尾实体抽取阶段，问题由模版和之前抽取的头实体生成。问题也可以是一个自然语言问题或者伪问题。例子在表3和表4中展示。<br>
<img src="https://kesblog.github.io/post-images/1566911094142.png" alt=""></p>
<figure data-type="image" tabindex="1"><img src="https://kesblog.github.io/post-images/1566911101076.png" alt=""></figure>
<h3 id="通过mrc来抽取答案">通过MRC来抽取答案</h3>
<p>在标准的MRC模型中，给定问题 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Q</mi><mo>=</mo><mrow><mo fence="true">{</mo><msub><mi>q</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>q</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>q</mi><msub><mi>N</mi><mi>q</mi></msub></msub><mo fence="true">}</mo></mrow></mrow><annotation encoding="application/x-tex">Q=\left\{q_{1}, q_{2}, \ldots, q_{N_{q}}\right\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">Q</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.20001em;vertical-align:-0.35001em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">{</span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833100000000004em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285716em;"><span style="top:-2.357em;margin-left:-0.10903em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">q</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2818857142857143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.34731999999999996em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">}</span></span></span></span></span></span> ，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>N</mi><mi>q</mi></msub></mrow><annotation encoding="application/x-tex">N_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 代表问题 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">Q</span></span></span></span> 的字数，上下文 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>C</mi><mo>=</mo><mrow><mo fence="true">{</mo><msub><mi>c</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>c</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>c</mi><msub><mi>N</mi><mi>c</mi></msub></msub><mo fence="true">}</mo></mrow></mrow><annotation encoding="application/x-tex">C=\left\{c_{1}, c_{2}, \ldots, c_{N_{c}}\right\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0001em;vertical-align:-0.2501em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">{</span><span class="mord"><span class="mord mathdefault">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285719em;"><span style="top:-2.357em;margin-left:-0.10903em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">}</span></span></span></span></span> ，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>N</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">N_c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 代表 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span></span></span></span> 的字数。我们需要预测答案。对于QA框架，我们使用BERT，输入为 [CLS, Q, SEP, C, SEP]。</p>
<p>传统的MRC模型使用两层softmax来预测起始和结束的位置。但是这种提取策略知识和单答案抽取问题，不适合我们的问题，因为一句话可能包含多个答案。为了解决这个问题，我们将这个问题形式化为一个机遇查询的标注问题。特别的，我们预测对每个 token 预测 BMEO标签。每个单词的表示输入到一层softmax层得到BMEO标签。可以认为我们正在把两个预测开始和结束位置的N类分类问题转化为N个5分类问题。</p>
<p>在训练阶段，我们联合的训练这两个阶段的目标</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mtable side="right"><mlabeledtr><mtd><mtext>(1)</mtext></mtd><mtd><mrow><mi mathvariant="script">L</mi><mo>=</mo><mo>(</mo><mn>1</mn><mo>−</mo><mi>λ</mi><mo>)</mo><mi mathvariant="script">L</mi><mo>(</mo><mtext> head-entity </mtext><mo>)</mo><mo>+</mo><mi>λ</mi><mi mathvariant="script">L</mi><mo>(</mo><mtext> tail-entity </mtext><mo separator="true">,</mo><mtext> rel </mtext><mo>)</mo></mrow></mtd></mlabeledtr></mtable><annotation encoding="application/x-tex">\mathcal{L}=(1-\lambda) \mathcal{L}(\text { head-entity })+\lambda \mathcal{L}(\text { tail-entity }, \text { rel })  \tag{1}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathcal">L</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">λ</span><span class="mclose">)</span><span class="mord"><span class="mord mathcal">L</span></span><span class="mopen">(</span><span class="mord text"><span class="mord"> head-entity </span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">λ</span><span class="mord"><span class="mord mathcal">L</span></span><span class="mopen">(</span><span class="mord text"><span class="mord"> tail-entity </span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord text"><span class="mord"> rel </span></span><span class="mclose">)</span></span><span class="tag"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">1</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>λ</mi><mo>∈</mo><mo>[</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo>]</mo></mrow><annotation encoding="application/x-tex">\lambda \in[0,1]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.73354em;vertical-align:-0.0391em;"></span><span class="mord mathdefault">λ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">1</span><span class="mclose">]</span></span></span></span> 是两阶段的控制参数。两个模型都适用标准BERT模型初始化。在测试阶段，头实体和尾实体被分别的在两个目标函数上抽取。</p>
<h3 id="增强学习">增强学习</h3>
<h2 id="实验">实验</h2>
<h3 id="resume上的结果">RESUME上的结果</h3>
<p>如表5中展示，tagging+dependency模型打败了tagging+relation模型，我们提出的多轮QA模型表现的最好，加上增强学习提升了效果。对于提取Person，只需要单轮QA，多轮的QA+RL模型和多轮QA模型表现相同。tagging+relation和tagging+dependency也是一样。<br>
<img src="https://kesblog.github.io/post-images/1566912635414.png" alt=""></p>
<h3 id="ace04ace05和conll04上的表现">ACE04，ACE05和CoNLL04上的表现</h3>
<p>对于ACE04，ACE05和CoNLL04数据集，只需要两轮QA。表6，7，8中展示了micro-F1 分数，准确率和召回率。对于ACE04，多轮QA模型比实体抽取的SOTA高 +1.8%，比关系抽取的SOTA高 +1.0%。对于ACE05，多轮QA模型比实体抽取的SOTA高 +1.2%，关系抽取的SOTA高 +0.6%。对于CoNLL04数据集，提出的多轮QA模型在关系F1上高 +2.1%<br>
<img src="https://kesblog.github.io/post-images/1566913117581.png" alt=""><br>
<img src="https://kesblog.github.io/post-images/1566913122500.png" alt=""><br>
<img src="https://kesblog.github.io/post-images/1566913128449.png" alt=""></p>
<h2 id="模型简化测试">模型简化测试</h2>
<h3 id="问题生成策略的影响">问题生成策略的影响</h3>
<p>我们对比了自然语言问题和伪问题，结果在表9。<br>
<img src="https://kesblog.github.io/post-images/1566913155926.png" alt=""></p>
<p>自然语言的F1在所有的数据集上更高。可能是因为自然语言提供了更好的语义信息，对实体关系抽取有帮助。伪问题非常粗糙，可能会误导模型。</p>
<h3 id="联合学习的影响">联合学习的影响</h3>
<p>我们将实体关系抽取任务分解成两个子任务：一个提取头实体的多答案任务和一个联合抽取关系和尾实体的单答案任务。我们联合训练这两个模型。<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">λ</span></span></span></span> 控制着这两个模型的取舍。</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mtable side="right"><mlabeledtr><mtd><mtext>(4)</mtext></mtd><mtd><mrow><mi mathvariant="script">L</mi><mo>=</mo><mo>(</mo><mn>1</mn><mo>−</mo><mi>λ</mi><mo>)</mo><mi mathvariant="script">L</mi><mo>(</mo><mtext> head-entity </mtext><mo>)</mo><mo>+</mo><mi>λ</mi><mi mathvariant="script">L</mi><mo>(</mo><mtext> tail-entity </mtext><mo>)</mo></mrow></mtd></mlabeledtr></mtable><annotation encoding="application/x-tex">\mathcal{L}=(1-\lambda) \mathcal{L}(\text { head-entity })+\lambda \mathcal{L}(\text { tail-entity }) \tag{4}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathcal">L</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">λ</span><span class="mclose">)</span><span class="mord"><span class="mord mathcal">L</span></span><span class="mopen">(</span><span class="mord text"><span class="mord"> head-entity </span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">λ</span><span class="mord"><span class="mord mathcal">L</span></span><span class="mopen">(</span><span class="mord text"><span class="mord"> tail-entity </span></span><span class="mclose">)</span></span><span class="tag"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">4</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>不同的 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">λ</span></span></span></span> 在ACE05数据集上的结果如下：<br>
<img src="https://kesblog.github.io/post-images/1566913656585.png" alt=""></p>
<p>当 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">λ</span></span></span></span> 设置为0时，系统之在头实体预测任务上训练。当 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>λ</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\lambda=0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">λ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> 时，没有取得最好的实体抽取结果，这可能是因为第二段的关系抽取对第一阶段的实体抽取有帮助，这更加确定要联合训练这两个任务。对于关系抽取任务，当 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>λ</mi><mo>=</mo><mn>0.7</mn></mrow><annotation encoding="application/x-tex">\lambda=0.7</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">λ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">7</span></span></span></span> 时，取得了最好的结果。</p>
<h3 id="样例学习">样例学习</h3>
<p>表10对比了我们提出的多轮QA模型和之前的SOTA MRT模型。在第一个例子中，MRT不能识别 <em>john scottsdale</em> 和 <em>iraq</em> 之间的关系，因为两个实体距离太远，但是我们的QA模型可以解决这个问题。<br>
<img src="https://kesblog.github.io/post-images/1566914060940.png" alt=""></p>
<p>在第二个例子中，句子包含了两对相同的关系，MRT模型很难识别处理这种情形，无法定位 <em>ship</em> 实体和气对应的关系，然而多轮QA模型可以解决这个问题。</p>
<h2 id="结论">结论</h2>
<p>在这篇文章中，我们提出了一个解决实体关系抽取任务的多轮问答范式。我们在3个数据集上取得了SOTA的结果。我们也构建了一个新的实体关系抽取数据集，要求层次关系推理并且提出的模型取得了最好的表现。</p>

        </div>

        
          <a class="animated fadeInUp p-2 items-center text-sm text-gray-700 border hover:bg-gray-300 leading-none rounded-full flex lg:inline-flex m-4 " href="https://kesblog.github.io/tag/nlp">
            <span class="flex-auto">NLP</span>
          </a>
        
          <a class="animated fadeInUp p-2 items-center text-sm text-gray-700 border hover:bg-gray-300 leading-none rounded-full flex lg:inline-flex m-4 " href="https://kesblog.github.io/tag/lun-wen-bi-ji">
            <span class="flex-auto">论文笔记</span>
          </a>
        


        <div class="flex justify-between py-8">
          
            <div class="prev-post">
              <a href="https://kesblog.github.io/post/extracting-multiple-relations-in-one-pass-with-pre-trained-transformers">
                <h3 class="post-title">
                  <i class="remixicon-arrow-left-line"></i>
                  Extracting Multiple-Relations in One-Pass with Pre-Trained Transformers
                </h3>
              </a>
            </div>
          

          
            <div class="next-post">
              <a href="https://kesblog.github.io/post/how-to-fine-tune-bert-for-text-classification">
                <h3 class="post-title">
                  How to Fine-Tune BERT for Text Classification
                  <i class="remixicon-arrow-right-line"></i>
                </h3>
              </a>
            </div>
          
        </div>

        

      </div>
    </div>

    <script src="https://kesblog.github.io/media/prism.js"></script>  
<script>

Prism.highlightAll()

let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

// This should probably be throttled.
// Especially because it triggers during smooth scrolling.
// https://lodash.com/docs/4.17.10#throttle
// You could do like...
// window.addEventListener("scroll", () => {
//    _.throttle(doThatStuff, 100);
// });
// Only not doing it here to keep this Pen dependency-free.

window.addEventListener("scroll", event => {
  let fromTop = window.scrollY;

  mainNavLinks.forEach((link, index) => {
    let section = document.getElementById(decodeURI(link.hash).substring(1));
    let nextSection = null
    if (mainNavLinks[index + 1]) {
      nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
    }
    if (section.offsetTop <= fromTop) {
      if (nextSection) {
        if (nextSection.offsetTop > fromTop) {
          link.classList.add("current");
        } else {
          link.classList.remove("current");    
        }
      } else {
        link.classList.add("current");
      }
    } else {
      link.classList.remove("current");
    }
  });
});


document.addEventListener("DOMContentLoaded", function() {
  var lazyImages = [].slice.call(document.querySelectorAll(".post-feature-image.lazy"));

  if ("IntersectionObserver" in window) {
    let lazyImageObserver = new IntersectionObserver(function(entries, observer) {
      entries.forEach(function(entry) {
        if (entry.isIntersecting) {
          let lazyImage = entry.target
          lazyImage.style.backgroundImage = `url(${lazyImage.dataset.bg})`
          lazyImage.classList.remove("lazy")
          lazyImageObserver.unobserve(lazyImage)
        }
      });
    });

    lazyImages.forEach(function(lazyImage) {
      lazyImageObserver.observe(lazyImage)
    })
  } else {
    // Possibly fall back to a more compatible method here
  }
});

const menuContainer = document.querySelector('.menu-container')
const menus = document.querySelectorAll('.menu-container .menu')
const mask = document.querySelector('.mask')
const contentWrapper = document.querySelector('.content-wrapper')
const latestArticle = document.querySelector('.latest-article')
const readMore = document.querySelector('.read-more')
const indexPage = document.querySelector('.index-page')

const isHome = location.pathname === '/'
if (latestArticle) {
  latestArticle.style.display = isHome ? 'block' : 'none'
  readMore.style.display = isHome ? 'block' : 'none'
  indexPage.style.display = isHome ? 'none' : 'block'
}

const openMenu = () => {
  menuContainer.classList.add('open')
  menus.forEach(menu => {
    menu.classList.add('animated', 'fadeInLeft')
  })
  mask.classList.add('open')
  contentWrapper.classList.add('is-second')
}

const closeMenu = () => {
  menuContainer.classList.remove('open')
  menus.forEach(menu => {
    menu.classList.remove('animated', 'fadeInLeft')
  })
  mask.classList.remove('open')
  contentWrapper.classList.remove('is-second')
}
</script>
  
  </body>
</html>
